name: AWS Infrastructure Deployment

on:
  push:
    branches: [main]
    paths-ignore:
      - '**.md'
      - 'docs/**'
      - '.github/ISSUE_TEMPLATE/**'
      - 'LICENSE'
      - '**/*.{png,jpg}'
  pull_request:
    branches: [develop]
    paths-ignore:
      - '**.md'
      - 'docs/**'
      - '.github/ISSUE_TEMPLATE/**'
      - 'LICENSE'
      - '**/*.{png,jpg}'
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

env:
  TF_LOG: INFO
  AWS_REGION: us-east-2
  ECR_REPOSITORY: nomadcrew
  TF_VERSION: 1.5.7

jobs:
  determine-environment:
    name: Determine Environment
    runs-on: ubuntu-latest
    outputs:
      environment: ${{ steps.set-env.outputs.environment }}
    steps:
      - id: set-env
        name: Set environment based on branch/event
        run: |
          if [[ "${{ github.event_name }}" == "pull_request" || "${{ github.ref }}" == "refs/heads/develop" ]]; then
            echo "environment=staging" >> $GITHUB_OUTPUT
          else
            echo "environment=production" >> $GITHUB_OUTPUT
          fi
          echo "Selected environment: $(cat $GITHUB_OUTPUT | grep environment | cut -d'=' -f2)"

  validate:
    name: Validate Terraform
    runs-on: ubuntu-latest
    needs: [determine-environment]
    outputs:
      fmt_outcome: ${{ steps.fmt.outcome }}
      init_outcome: ${{ steps.init.outcome }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ env.TF_VERSION }}
          cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

      - name: Cache Terraform plugins
        uses: actions/cache@v3
        with:
          path: ~/.terraform.d/plugin-cache
          key: ${{ runner.os }}-terraform-${{ hashFiles('**/.terraform.lock.hcl') }}
          restore-keys: |
            ${{ runner.os }}-terraform-

      - id: fmt
        name: Terraform Format
        run: terraform fmt -check -recursive

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ needs.determine-environment.outputs.environment == 'production' && 'arn:aws:iam::195275657852:role/NomadCrewProductionDeploymentRole' || 'arn:aws:iam::195275657852:role/NomadCrewStagingDeploymentRole' }}
          aws-region: ${{ env.AWS_REGION }}

      - id: init
        name: Terraform Init
        working-directory: terraform
        run: terraform init -input=false

      - id: validate
        name: Terraform Validate
        working-directory: terraform
        run: terraform validate -no-color

  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Run tfsec
        uses: aquasecurity/tfsec-action@v1.0.0
        with:
          working_directory: terraform
          format: sarif
          soft_fail: true

      - name: Upload SARIF file
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: tfsec.sarif

  plan:
    name: Plan Terraform Changes
    needs: [validate, security-scan, determine-environment]
    runs-on: ubuntu-latest
    outputs:
      has_changes: ${{ steps.plan.outputs.has_changes }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ needs.determine-environment.outputs.environment == 'production' && 'arn:aws:iam::195275657852:role/NomadCrewProductionDeploymentRole' || 'arn:aws:iam::195275657852:role/NomadCrewStagingDeploymentRole' }}
          aws-region: ${{ env.AWS_REGION }}

      - id: init
        name: Terraform Init
        working-directory: terraform
        run: terraform init -input=false

      - name: Set Terraform Workspace
        working-directory: terraform
        run: |
          terraform workspace select ${{ needs.determine-environment.outputs.environment }} || terraform workspace new ${{ needs.determine-environment.outputs.environment }}

      - id: plan
        name: Terraform Plan
        working-directory: terraform
        continue-on-error: true
        run: |
          terraform plan -no-color -refresh=false -var="environment=${{ needs.determine-environment.outputs.environment }}" \
            -var="supabase_anon_key=${{ secrets.SUPABASE_ANON_KEY }}" \
            -var="supabase_url=${{ secrets.SUPABASE_URL }}" \
            -var="google_web_client_id=${{ secrets.GOOGLE_WEB_CLIENT_ID }}" \
            -var="google_places_api_key=${{ secrets.GOOGLE_PLACES_API_KEY }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="redis_password=${{ secrets.REDIS_PASSWORD }}" \
            -var="jwt_secret_key=${{ secrets.JWT_SECRET_KEY }}" -out=plan.txt

          # Save plan output for PR comment
          echo "plan_output<<EOF" >> $GITHUB_OUTPUT
          cat plan.txt >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

          # Determine if there are changes
          if grep -q "No changes. Infrastructure is up-to-date." plan.txt; then
            echo "has_changes=false" >> $GITHUB_OUTPUT
          else
            echo "has_changes=true" >> $GITHUB_OUTPUT
          fi

      - name: Comment Plan
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const output = `#### Terraform Format and Style üñå\`${{ steps.fmt.outcome }}\`
            #### Terraform Initialization ‚öôÔ∏è\`${{ steps.init.outcome }}\`
            #### Terraform Plan üìñ\`${{ steps.plan.outcome }}\`
            <details><summary>Show Plan</summary>

            \`\`\`terraform
            ${{ steps.plan.outputs.plan_output }}
            \`\`\`

            </details>

            *Pushed by: @${{ github.actor }}, Action: \`${{ github.event_name }}\`*`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: output
            })

  build-and-push:
    name: Build and Push Docker Image
    runs-on: ubuntu-latest
    needs: [determine-environment]
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
    outputs:
      image_tag: ${{ steps.set-image-tag.outputs.image_tag }}
      registry_url: ${{ steps.login-ecr.outputs.registry }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ needs.determine-environment.outputs.environment == 'production' && 'arn:aws:iam::195275657852:role/NomadCrewProductionDeploymentRole' || 'arn:aws:iam::195275657852:role/NomadCrewStagingDeploymentRole' }}
          aws-region: ${{ env.AWS_REGION }}

      - id: login-ecr
        name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v1

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Build and push Docker image
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          tags: ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ github.sha }},${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            SERVER_ENVIRONMENT=${{ needs.determine-environment.outputs.environment }}
            JWT_SECRET_KEY=${{ secrets.JWT_SECRET_KEY }}
            DB_PASSWORD=${{ secrets.DB_PASSWORD }}
            REDIS_PASSWORD=${{ secrets.REDIS_PASSWORD }}
            RESEND_API_KEY=${{ secrets.RESEND_API_KEY }}
            GEOAPIFY_KEY=${{ secrets.GEOAPIFY_KEY }}
            PEXELS_API_KEY=${{ secrets.PEXELS_API_KEY }}
            SUPABASE_ANON_KEY=${{ secrets.SUPABASE_ANON_KEY }}
            SUPABASE_SERVICE_KEY=${{ secrets.SUPABASE_SERVICE_KEY }}
            SUPABASE_URL=${{ secrets.SUPABASE_URL }}
            SUPABASE_JWT_SECRET=${{ secrets.SUPABASE_JWT_SECRET }}
            EMAIL_FROM_ADDRESS=${{ secrets.EMAIL_FROM_ADDRESS }}
            EMAIL_FROM_NAME=${{ secrets.EMAIL_FROM_NAME }}
            FRONTEND_URL=${{ secrets.FRONTEND_URL }}
            ALLOWED_ORIGINS=${{ secrets.ALLOWED_ORIGINS }}

      - id: set-image-tag
        name: Set image tag output
        run: echo "image_tag=${{ github.sha }}" >> $GITHUB_OUTPUT

  deploy:
    name: Deploy Infrastructure
    needs: [plan, build-and-push, determine-environment]
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ needs.determine-environment.outputs.environment == 'production' && 'arn:aws:iam::195275657852:role/NomadCrewProductionDeploymentRole' || 'arn:aws:iam::195275657852:role/NomadCrewStagingDeploymentRole' }}
          aws-region: ${{ env.AWS_REGION }}
          role-duration-seconds: 3600

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Terraform Init
        working-directory: terraform
        run: terraform init -input=false

      - name: Set Terraform Workspace
        working-directory: terraform
        run: |
          terraform workspace select ${{ needs.determine-environment.outputs.environment }} || terraform workspace new ${{ needs.determine-environment.outputs.environment }}

      - id: check-changes
        name: Check for infrastructure changes
        working-directory: terraform
        run: |
          terraform plan -detailed-exitcode \
            -var="environment=${{ needs.determine-environment.outputs.environment }}" \
            -var="supabase_anon_key=${{ secrets.SUPABASE_ANON_KEY }}" \
            -var="supabase_url=${{ secrets.SUPABASE_URL }}" \
            -var="google_web_client_id=${{ secrets.GOOGLE_WEB_CLIENT_ID }}" \
            -var="google_places_api_key=${{ secrets.GOOGLE_PLACES_API_KEY }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="redis_password=${{ secrets.REDIS_PASSWORD }}" \
            -var="jwt_secret_key=${{ secrets.JWT_SECRET_KEY }}" \
            -var="docker_image=${{ needs.build-and-push.outputs.image_tag }}" > /dev/null || echo "has_changes=true" >> $GITHUB_OUTPUT

      - name: Terraform Apply
        if: steps.check-changes.outputs.has_changes == 'true'
        working-directory: terraform
        run: |
          terraform apply -auto-approve \
            -var="environment=${{ needs.determine-environment.outputs.environment }}" \
            -var="supabase_anon_key=${{ secrets.SUPABASE_ANON_KEY }}" \
            -var="supabase_url=${{ secrets.SUPABASE_URL }}" \
            -var="google_web_client_id=${{ secrets.GOOGLE_WEB_CLIENT_ID }}" \
            -var="google_places_api_key=${{ secrets.GOOGLE_PLACES_API_KEY }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="redis_password=${{ secrets.REDIS_PASSWORD }}" \
            -var="jwt_secret_key=${{ secrets.JWT_SECRET_KEY }}" \
            -var="docker_image=${{ needs.build-and-push.outputs.image_tag }}"

      - name: Login to Amazon ECR for Deploy
        id: login-ecr-deploy
        uses: aws-actions/amazon-ecr-login@v1

      - name: Configure kubectl
        run: |
          aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name nomad-crew-cluster-${{ needs.determine-environment.outputs.environment }}

      - name: Deploy to Kubernetes
        run: |
          kubectl set image deployment/nomad-crew-frontend nomad-crew-frontend=${{ needs.build-and-push.outputs.registry_url }}/${{ env.ECR_REPOSITORY }}:${{ needs.build-and-push.outputs.image_tag }} --record
          kubectl rollout status deployment/nomad-crew-frontend

      - name: Set up rollback capability
        run: |
          CURRENT_REVISION=$(kubectl get deployment/nomad-crew-frontend -o jsonpath='{.metadata.annotations.deployment\.kubernetes\.io/revision}')
          echo "CURRENT_REVISION=$CURRENT_REVISION" >> $GITHUB_ENV

  verify-deployment:
    name: Verify Deployment
    needs: [deploy, build-and-push, determine-environment]
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ needs.determine-environment.outputs.environment == 'production' && 'arn:aws:iam::195275657852:role/NomadCrewProductionDeploymentRole' || 'arn:aws:iam::195275657852:role/NomadCrewStagingDeploymentRole' }}
          aws-region: ${{ env.AWS_REGION }}

      - id: health-check
        name: Check application health
        run: |
          # Get the load balancer DNS
          ALB_DNS=$(aws elbv2 describe-load-balancers --query "LoadBalancers[?contains(LoadBalancerName, 'nomadcrew')].DNSName" --output text)
          echo "Checking application health at https://$ALB_DNS/health/liveness"
          
          # Attempt health check up to 10 times
          for i in {1..10}; do
            HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" https://$ALB_DNS/health/liveness)
            
            if [ "$HTTP_STATUS" -eq 200 ]; then
              echo "Application is healthy!"
              exit 0
            else
              echo "Attempt $i: Application is not healthy yet. Status: $HTTP_STATUS"
              sleep 30
            fi
          done
          
          echo "Application failed to become healthy after multiple attempts."
          exit 1

      - name: Rollback on failure
        if: failure() && steps.health-check.outcome == 'failure'
        run: |
          # Configure kubectl for rollback
          aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name nomad-crew-cluster-${{ needs.determine-environment.outputs.environment }}
          
          echo "Health check failed, rolling back deployment..."
          kubectl rollout undo deployment/nomad-crew-frontend
          kubectl rollout status deployment/nomad-crew-frontend
          
          echo "Rollback completed. Please check the application logs for more details."
